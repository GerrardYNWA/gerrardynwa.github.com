title: VINS-Mono---A Robust and Versatile Monocular Visual-Inertial State Estimator
date: 2018-10-04 21:49:48
categories: Translation

tags: [computer vision]
---

VINS-Mono的粗略翻译。。。

<!-- more -->

### Abstract

　　由摄像机和低成本惯性测量单元(IMU)组成的单目视觉惯性系统(VINS)，构成了用于度量六自由度状态估计的最小传感器套件。然而，由于缺乏直接距离测量，这套系统在IMU处理、估计器初始化、外部标定和非线性优化等方面面临着诸多挑战。在本文中，我们提出了一种鲁棒的、通用的单目视觉惯性状态估计器VINS-Mono。我们的方法从一个稳健的程序开始，用于估计器初始化和故障恢复。采用一种基于紧耦合、非线性优化的方法，通过融合预计分的IMU测量数据和特征观测数据，获得高精度的视觉惯性里程计。结合我们紧耦合的公式，一个闭环检测模块能够以最小的计算开销进行重定位。除此之外，我们还对四自由度姿态图进行了优化，以加强全局一致性。我们验证了该系统在公共数据集和真实环境实验的性能，并与其他最先进的算法进行了比较。我们还在MAV平台上执行机载闭环自主飞行，并将算法移植到基于iOS的demo中。特别强调的是，本文提出的工作是一个可靠、完整和通用的系统，适用于需要高精度定位的不同应用。我们为PC和iOS移动设备开源了我们的实现方法。

### Index Terms-单目视觉惯性系统，状态估计，传感器融合，SLAM

### 1. Introduction

　　状态估计无疑是机器人导航、自主驾驶、虚拟现实(VR)和增强现实(AR)等广泛应用中最基本的模块。仅使用单目摄像机的方法由于其体积小、成本低和硬件设置简单而获得了社会的极大兴趣[1]-[5]。然而，单目视觉系统无法恢复度量尺度，因此限制了它们在实际机器人中的应用。近年来，我们看到了一种发展趋势，即用低成本惯性测量单元(IMU)辅助单目视觉系统。这种单目视觉-惯性系统(VINS)的主要优点是具有可观测的度量尺度，以及翻滚角(roll)和俯仰角(pitch)。这让需要有尺度的状态估计的导航任务成为可能。此外，对IMU测量值的积分可以显著提高运动跟踪性能，弥补光照变化、缺少纹理的区域或运动模糊的视觉轨迹损失的差距。事实上，单目VINS不仅广泛应用于移动机器人、无人机和移动设备上，还是满足充分自我感知和环境感知的最小传感器。

　　然而，所有这些优点都是有代价的。对于单目VINS，众所周知，需要加速度激励以测量尺度。这意味着单目VIN估计器不能从静止状态启动，而是从未知的移动状态发动。同时要认识到视觉惯性系统高度非线性的事实，在估计器初始化方面还有重大挑战。两个传感器的存在也使得摄像机-IMU的外部校准至关重要。最后，为了消除在可接受的处理窗口内的长期漂移，提出了一个完整的系统，包括视觉惯性里程计、回环检测、重定位和全局优化。

　　为了解决所有这些问题，我们提出了VINS-Mono，一个鲁棒且通用的单目视觉惯性状态估计器。我们的解决方案开始于即时估计初始化。这个初始化模块也用于故障恢复。我们的解决方案的核心是一个鲁棒的基于紧耦合的滑动窗非线性优化的单目视觉惯性里程计(VIO)。单目VIO模块不仅提供精确的局部姿态、速度和方位估计，而且还以在线方式执行摄像机IMU外部校准和IMU偏置校正。使用DBoW2[6]进行回环检测。重新定位是在对单目VIO进行特征级别融合的紧耦合设置中完成。这使得重新定位具有鲁棒性和精确性且有最小的计算代价。最后，几何验证的回环被添加到位姿图中，并且由于来自单目VIO的可观测的翻滚角和俯仰角，生成四自由度(DOF)位姿图以确保全局一致性。

　　VINS-Mono结合并改进了我们先前在单目视觉-惯性融合方面的工作[7]-[10]。它建立在我们紧耦合、基于优化的单目VIO的公式之上[7][8]，并结合了[9]中引入的改进初始化过程。[10]中给出了移植到移动设备的第一次尝试。与我们以前的工作相比，VINS-Mono的进一步改进包括改进的含偏置校正的IMU预积分、紧耦合重定位、全局位姿图优化、广泛的实验评估以及鲁棒和通用的开源实现。

　　整个系统完整且易于使用。它已经被成功应用于小规模AR场景、中型无人机导航和大规模状态估计任务。与其他最先进的方法相比具有优异的性能。为此，我们总结了我们的贡献，如下所示：

> 1. 一个鲁棒的初始化过程，它能够从未知的初始状态引导系统。
> 2. 一个紧耦合、基于优化的单目视觉惯性里程计，具有相机-IMU外部校准和IMU偏置估计。
> 3. 在线回环检测与紧耦合重定位。
> 4. 四自由度全局位姿图优化。
> 5. 用于无人机导航、大规模定位和移动AR应用的实时性能演示。
> 6. 完全集成于ros的pc版本以及可在iphone 6或更高版本上运行的IOS版本的开源代码。

　　论文的其余部分如下：在第二节中，我们讨论了相关的文献。在第三节中，我们对完整的系统框架进行了概述。在第四节中，给出了视觉的预处理和IMU测量值的预积分步骤。在第五节中，我们讨论了估计器的初始化过程。在第六节中提出了一种紧耦合、自标定、非线性优化的单目VIO。第七节和第八节分别给出了紧耦合重定位和全局位姿图优化。实施细节和实验结果见第九节。最后，在第十节本文对研究方向进行了探讨和展望。

### 2. Related Work

　　目前基于单目视觉的状态估计/里程测量/SLAM相关的学术著作众多，值得注意的方法包括PTAM、SVO、LSD-SLAM、DSO和ORB-SLAM。显然，对其进行全面回顾是不太可能的。然而，在这一节中，我们跳过了关于只使用视觉的方法的讨论，而只专注于关于单目视觉惯性状态估计的最相关的结果。

　　处理视觉和惯性测量的最简单的方法是**松耦合**传感器融合，其中IMU被视为一个独立的模块，用于辅助从运动中获得的视觉结构的视觉姿态估计。融合通常由扩展卡尔曼滤波(EKF)完成，**其中IMU用于状态传播，而视觉姿态用于更新**。进一步说，**紧耦合视觉惯性算法要么基于EKF，要么基于图优化**，其中摄像机和IMU测量是从原始测量水平联合优化的。一种流行的基于EKF的VIO方法是MSCKF。MSCKF在状态向量中维护以前的几个摄像机姿态，并使用多个摄像机视图中相同特征的视觉测量来形成多约束更新。SR-ISWF是MSCKF的扩展。它采用SQuareroot格式实现单精度表示，避免了差的数值性质。该方法采用逆滤波器进行迭代再线性化，使其与基于优化的算法相当.批量图优化或捆绑调整（BA）技术维护和优化所有的测量，以获得最优状态估计。为了达到恒定的处理时间，流行的基于图的VIO方法通常通过边缘化有过去的状态和测量的有界滑动窗口来优化最近状态。由于对非线性系统迭代求解的计算要求很高，很少有基于图的非线性系统能够在资源受限的平台(如手机)上实现实时性能。

　　对于视觉测量处理，根据**视觉残差模型的定义，算法可分为直接法和间接法。**直接法最小光度误差，而间接法最小几何位移。直接方法由于其吸引区域小，需要很好的初始估计，而间接方法在提取和匹配特征时需要额外的计算资源。**间接方法由于其成熟性和鲁棒性，在实际工程部署中得到了广泛的应用。**然而，直接方法更容易扩展到稠密建图，因为它们是直接在像素级别上操作的。

　　在实践中，IMU通常以比摄像机更高的速度获取数据。不同的方法被提出来处理高速率的IMU测量。最简单的方法是在基于EKF的方法中使用IMU进行状态传播。在图优化公式中，为了避免重复的IMU重复积分，提出了一种有效的方法，即IMU预积分，这种方法是在[22]中首次提出的，它用欧拉角来参数化旋转误差。在我们先前的工作中，我们提出了一种流形上的IMU-preIntegration旋转公式，该文利用连续IMU误差状态动力学推导了协方差传播。然而，IMU偏置被忽略了。文[23]通过增加后验IMU偏置校正，进一步改进了预积分理论。

　　精确的初始值对于引导任何单目VINS是至关重要的。在[8]，[24]中提出了一种利用短期IMU预积分相对旋转的线性估计器初始化方法。但是，该方法不对陀螺仪偏置进行建模，无法在原始投影方程中对传感器噪声进行建模。在实际应用中，当视觉特性远离传感器套件时，这会导致不可靠的初始化。文[25]给出了单目视觉惯性初始化问题的一种封闭解.随后，文[26]提出了对这种封闭形式的解决方案的扩展，增加了陀螺仪的偏置校准。这些方法依赖于长时间内IMU测量的双重积分，无法模拟惯性积分的不确定性。在[27]中，提出了一种基于SVO的重初始化和故障恢复算法.这是一种基于松散耦合融合框架的实用方法。然而，需要额外的朝下的距离传感器来恢复公制尺度.在[17]中引入了一种建立在流行的ORB-SLAM之上的初始化算法.给出了一组ORB-SLAM的关键帧，计算了视觉惯性全BA的尺度、重力方向、速度和IMU偏置的初步估计。然而，据报道，规模收敛所需的时间可能超过10秒。这可能会给需要在一开始就进行规模评估的机器人导航任务带来问题。

　　VIO方法，不管它们所依赖的基本数学公式，在全局的平移和旋转中长期受到漂移的影响。为此，回环检测在长期操作中起着重要的作用.ORBSLAM能够关闭循环并重新使用地图，它利用了词袋模型。一个7自由度（位置、方向和尺度)的姿态图优化遵循回环检测。相对于单目Vins，由于IMU的加入，漂移只发生在4自由度，即三维平移，并围绕重力方向(偏航角)旋转。因此，本文选择在最小四自由度设定下，优化具有回路约束的姿态图。

### 3. Overview

　　提出的单目视觉惯性状态估计器的结构如图2所示。该系统从测量预处理(IV)开始，在其中提取和跟踪特征，对两个连续帧间的IMU测量值进行预积分。初始化过程(V)提供了所有必要的值，包括姿态、速度、重力向量、陀螺仪偏置和三维特征位置，用于引导随后的基于非线性优化的VIO。VIO(VI)与重定位(VII)模块紧密地融合了预先积分的IMU测量、特征观测和回环重新检测到的特征。最后，位姿图优化模块(VIII)接受几何验证的重定位结果，并进行全局优化以消除漂移。VIO、重新定位和位姿图优化模块在多线程设置中同时运行。每个模块有不同的运行速度和实时保证，以确保在任何时候可靠运行。

　　我们现在对整篇论文中使用的符号和坐标系进行定义。我们认为$ (·)^{\omega} $是世界坐标系(world frame)。重力方向与世界坐标系$ z $轴对齐。$ (·)^b $是本体坐标系(body frame)，我们把它定义为与IMU坐标系相同。$ (·)^c $是相机坐标系(camera frame)。我们同时使用旋转矩阵$ R $和Hamilton四元数$ q $来表示旋转。我们主要在状态向量中使用四元数，也用旋转矩阵来表示三维向量的旋转。$ q_{b}^{\omega} $、$ p_{b}^{\omega} $表示从本体坐标系到世界坐标系的旋转和平移。$ b_k $表示获取第$ k $个图像时的相机坐标系。$ \otimes $表示两个四元数之间的乘法运算。$ g_{\omega} = [0, 0, g]^T $是世界坐标系上的重力向量。最后，我们将$ (\hat{}) $表示为某一具体量的噪声测量值或估计值。

### 4. Measurement Preprocessing

　　本节介绍VIO的预处理步骤。对于视觉测量，我们跟踪连续帧之间的特征，并在最新帧中检测新特征。对于IMU测量，我们在两个连续帧之间做预积分。请注意，我们使用的低成本IMU的测量值受到偏置和噪声的影响。因此，我们在IMU预积分过程中特别考虑偏置。

#### A. Vision Processing Front End

　　对于每一幅新图像，KLT稀疏光流算法对现有特征进行跟踪[29]。同时，检测新的角点特征[30]以保证每个图像特征的最小数目(100-300)。该检测器通过设置两个相邻特征之间像素的最小间隔来执行均匀的特征分布。二维特征首先是不失真的，然后在通过外点剔除后投影到一个单位球面上。利用基本矩阵模型的RANSAC算法进行外点剔除。

　　在此步骤中还选择了关键帧。我们有两个关键帧选择标准。第一是与上一个关键帧的平均视差。如果在当前帧和最新关键帧之间跟踪的特征点的平均视差超出某个特定阈值，则将该帧视为新的关键帧。请注意，不仅平移，旋转也会产生视差。然而，特征点无法在纯旋转运动中三角化。为了避免这种情况，在计算视差时我们使用陀螺仪测量值的短时积分来补偿旋转。请注意，此旋转补偿仅用于关键帧选择，而不涉及VINS公式中的旋转计算。为此，即使陀螺仪含有较大的噪声或存在偏置，也只会导致次优的关键帧选择结果，不会直接影响估计质量。另一个标准是跟踪质量。如果跟踪的特征数量低于某一阈值，我们将此帧视为新的关键帧。这个标准是为了避免跟踪特征完全丢失。

#### B. IMU Preinteration

　　IMU预积分是在[22]中首次提出的，它将欧拉角的旋转误差参数化。在我们先前的工作中[7]，我们提出了一个流形上的IMU预积分旋转公式。该文利用连续时间的IMU误差状态动力学推导协方差传递函数，但忽略了IMU偏置。文[23]通过增加后验IMU偏置校正，进一步改进了预积分理论。本文通过引入IMU偏置校正，扩展了我们在前面工作[7]中提出的IMU预积分。

　　IMU的原始陀螺仪和加速度计测量结果wˆ\hat w*w*^和aˆ\hat a*a*^如下：

　　IMU测量值是在本体坐标系中测量的，它是平衡重力和平台动力的合力，并受到加速度偏置ba、陀螺仪偏置bw和附加噪声的影响。假设加速度计和陀螺仪测量值中的附加噪声为高斯噪声，na∼N(0,σ2a)n_a∼N(0,σ_a^2)*n**a*∼*N*(0,*σ**a*2)，nw∼N(0,σ2w)n_w∼N(0,σ_w^2)*n**w*∼*N*(0,*σ**w*2)。加速度计偏置和陀螺仪偏置被建模为随机游走，其导数为高斯性的，nba∼N(0,σ2ba)n_{b_a}∼N(0,σ_{b_a}^2)*n**b**a*∼*N*(0,*σ**b**a*2)，nbw∼N(0,σ2bw)n_{b_w}∼N(0,σ_{b_w}^2)*n**b**w*∼*N*(0,*σ**b**w*2)。

　　给定对应于体坐标系bk和bk+1的两个时刻，位置、速度和方向状态可以在时间间隔[tk,tk+1]间，在世界坐标系下中通过惯性测量值传递：

　　∆tk是时间间隔[tk,tk+1]之间的持续时间。

　　可见，IMU状态传递需要坐标系bk的旋转、位置和速度。当这些起始状态改变时，我们需要重新传递IMU测量值。特别是在基于优化的算法中，每次调整位姿时，都需要在它们之间重新传递IMU测量值。这种传递策略在计算上要求很高。为了避免重新传递，我们采用了预积分算法。

　　将参考坐标系从世界坐标系转变为局部坐标系bk后，我们只能对线性的加速度aˆ\hat a*a*^和角速度wˆ\hat w*w*^相关的部分进行预积分，如下所示：

　　可以看出预积分项(6)能通过将bk视为参考帧的IMU测量值单独得到。αbkbk+1、βbkbk+1、γbkbk+1α_{b_{k+1}}^{bk}、β_{b_{k+1}}^{bk}、γ_{b_{k+1}}^{bk}*α**b**k*+1*b**k*、*β**b**k*+1*b**k*、*γ**b**k*+1*b**k*只与bk和bk+1中的IMU偏置有关，与其他状态无关。当偏置估计发生变化时，若偏置变化很小，我们将αbkbk+1、βbkbk+1、γbkbk+1α_{b_{k+1}}^{bk}、β_{b_{k+1}}^{bk}、γ_{b_{k+1}}^{bk}*α**b**k*+1*b**k*、*β**b**k*+1*b**k*、*γ**b**k*+1*b**k*按其对偏置的一阶近似来调整，否则就进行重新传递。这种策略为基于优化的算法节省了大量的计算资源，因为我们不需要重复传递IMU测量值。

### 5. Estimator Initialization

　　单目紧耦合VIO是一个高度非线性的系统。由于单目相机无法直接观测到尺度，因此，如果没有良好的初始值，很难直接将这两种测量结果融合在一起。可以假设一个静止的初始条件来启动单目VINS估计器。然而，这种假设是不合适的，因为在实际应用中经常会遇到运动下的初始化。当IMU测量结果被大偏置破坏时，情况就变得更加复杂了。事实上，初始化通常是单目VINS最脆弱的步骤。需要一个鲁棒的初始化过程以确保系统的适用性。

　　我们采用松耦合的传感器融合方法得到初始值。我们发现纯视觉SLAM，或从运动中恢复结构(SfM)，具有良好的初始化性质。在大多数情况下，纯视觉系统可以通过从相对运动方法（如八点法[32]或五点法[33]或估计单应性矩阵）中导出初始值来引导自己。通过对齐IMU预积分与纯视觉SfM结果，我们可以粗略地恢复尺度、重力、速度，甚至偏置。这足以引导非线性单目VINS估计器，如图4所示。

　　与在初始阶段同时估计陀螺仪和加速度计偏置的[17]相比，我们在初始阶段选择忽略加速度计偏置项。加速度计偏置与重力耦合，且由于重力向量相对于平台动力学的大量级，以及初始阶段相对较短，这些偏置项很难被观测到。我们以前的工作对加速度计偏置标定进行了详细的分析[34]。

#### A. Vision-Only SfM in Sliding Window

　　初始化过程从纯视觉SfM估计相机尺度位姿(up-to-scale)和特征位置图开始。

　　我们保持了一个帧的滑动窗口来限制计算复杂度。首先，我们检查了最新帧与之前所有帧之间的特征对应。如果我们能在滑动窗口中的最新帧和任何其他帧之间，找到稳定的特征跟踪(超过30个跟踪特征)和足够的视差(超过20个的旋转补偿像素)，我们使用五点法[33]恢复这两个帧之间的相对旋转和尺度平移。否则，我们将最新的帧保存在窗口中，并等待新的帧。如果五点算法成功的话，我们任意设置尺度，并对这两个帧中观察到的所有特征进行三角化。基于这些三角特征，采用PnP[35]来估计窗口中所有其他帧的姿态。最后，应用全局光束平差法(BA)[36]最小化所有特征观测的重投影误差。由于我们还没有任何世界坐标系的知识，我们将第一个相机坐标系(·)c0设置为SfM的参考坐标系。所有帧的位姿(p‾c0ck，qc0ck)( \overline p_{c_k}^{c_0}，q_{c_k}^{c_0})(*p**c**k**c*0，*q**c**k**c*0)和特征位置表示相对于(·)c0。假设摄像机和IMU之间有一个粗略测量的外部参数(pbc,qbc)(p_c^b,q_c^b)(*p**c**b*,*q**c**b*)，我们可以将姿态从相机坐标系转换到物体(IMU)坐标系。

　　其中s是匹配视觉结构与距离尺度的尺度参数，解出尺度参数是实现成功初始化的关键。

#### B. Visual-Inertial Alignment

　　1) Gyroscope Bias Calibration: 考虑窗口中连续两帧bk和bk+1，我们从视觉sfM中得到旋转qc0bkq_{b_k}^{c_0}*q**b**k**c*0和qc0bk+1q_{b_{k+1}}^{c_0}*q**b**k*+1*c*0，从IMU预积分得到的相对约束γˆbkbk+1\hat γ_{b_{k+1}}^{bk}*γ*^*b**k*+1*b**k*。我们对陀螺仪偏置求IMU预积分项的线性化，并最小化以下代价函数：

　　其中B代表窗口的所有帧。利用第四部分导出的偏置雅可比，给出了γˆbkbk+1\hat γ_{b_{k+1}}^{bk}*γ*^*b**k*+1*b**k*对陀螺仪偏置的一阶近似。这样，我们得到了陀螺仪偏置bw的初始校准。然后我们用新的陀螺仪偏置重新传递所有的IMU预积分项αˆbkbk+1、βˆbkbk+1、γˆbkbk+1\hat α_{b_{k+1}}^{bk}、\hat β_{b_{k+1}}^{bk}、\hat γ_{b_{k+1}}^{bk}*α*^*b**k*+1*b**k*、*β*^*b**k*+1*b**k*、*γ*^*b**k*+1*b**k*。

　　2) Velocity, Gravity Vector, and Metric Scale Initialization: 在陀螺仪偏置初始化后，我们继续初始化导航的其他基本状态，即速度、重力向量和尺度：

　　其中，vbkbkv_{b_k}^{b_k}*v**b**k**b**k*是第k帧图像本体坐标系的速度，gc0g^{c_0}*g**c*0是c0坐标系中的重力向量，s是单目SfM到公制单位的尺度。

　　考虑窗口中两个连续帧bk和bk+1，那么(5)可以写成：

　　我们可以将(14)和(17)合并成以下线性测量模型：

　　可以看出，Rc0bk，Rc0bk+1，p‾c0ck，p‾c0ck+1R_{b_k}^{c_0}，R_{b_{k+1}}^{c_0}， \overline p_{c_k}^{c_0}， \overline p_{c_{k+1}}^{c_0}*R**b**k**c*0，*R**b**k*+1*c*0，*p**c**k**c*0，*p**c**k*+1*c*0是从带尺度的单目视觉中得到的，∆tk是两个连续帧之间的时间间隔。通过求解线性最小二乘问题：

　　我们可以得到窗口中每一帧的本体坐标系速度，视觉参照系(·)c0的重力向量，以及尺度参数。

　　3) Gravity Refinement: 通过约束量值，可以对原线性初始化步骤得到的重力向量进行细化。在大多数情况下，重力向量的大小是已知的。这导致重力向量只剩2个自由度。因此，我们在其切线空间上用两个变量重新参数化重力。参数化将重力向量表示为

　　其中g是已知的重力大小，gˆ‾‾\overline {\hat g}*g*^是表示重力方向的单位向量，b1和b2是跨越切平面的两个正交基，如图5所示，w1和w2分别是在b1和b2上的对应位移。通过算法1的叉乘运算，可以找到一组b1、b2。然后用

　　代替(17)中的g，并与其它状态变量一起求解w1和w2。此过程迭代到gˆ‾‾\overline {\hat g}*g*^收敛为止。

　　4) Completing Initialization: 经过对重力向量的细化，通过将重力旋转到z轴上，得到世界坐标系与摄像机坐标系c0之间的旋转qwc0q_{c_0}^w*q**c*0*w*。然后我们将所有变量从参考坐标系(·)c0 旋转到世界坐标系(·)w。本体坐标系的速度也将被旋转到世界坐标系。视觉SfM的变换矩阵将被缩放到度量单位。此时，初始化过程已经完成，所有这些度量值都将被输入到一个紧耦合的单目VIO中。

### 6. Tightly Coupled Monocular VIO

　　在估计器初始化后，我们采用基于滑动窗口的紧耦合单目VIO进行高精度和鲁棒的状态估计。图3显示了滑动窗口的图示。

#### A. Formulation

　　滑动窗口中的完整状态向量定义为：

　　其中xk是捕获第k图像时的IMU状态。它包含了IMU在世界坐标系中的位置、速度和方向，以及在IMU本体坐标系中的加速度计偏置和陀螺仪偏置。n是关键帧的总数，m是滑动窗口中的特征总数，λl是第一次观测到第l个特征的逆深度。

　　我们使用视觉惯性BA。我们最小化所有测量残差的先验和Mahalanobis范数之和，得到最大后验估计：

　　其中Huber范数[37]被定义为：

*　　r**B*(*z*^*b**k*+1*b**k*,*X*)和rC(zˆcjl,X)r_C(\hat z_l^{c_j},X)*r**C*(*z*^*l**c**j*,*X*)分别是IMU和视觉测量的残差。残差的详细定义将在第六节的B和C中提出。B是所有IMU测量的集合，C是在当前滑动窗口中至少观察到两次的一组特征。{rp,**H**p}\{r_p,\textbf H_p\}{*r**p*,**H***p*}是来自边缘化的先验信息。Ceres Solver[38]被用来解决这个非线性问题。

### 7. Relocalization

### 8. Global Pose Graph Optimization and Map Reuse

### 9. Experimental Results

### 10. Conclusion and Future Work





